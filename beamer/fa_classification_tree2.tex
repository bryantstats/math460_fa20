% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Classification Trees},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\newif\ifbibliography
\usepackage{longtable,booktabs}
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Classification Trees}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\frame{\titlepage}

\begin{frame}{Classification Trees}
\protect\hypertarget{classification-trees}{}

author: Son Nguyen

\end{frame}

\begin{frame}{Reading Materials}
\protect\hypertarget{reading-materials}{}

\begin{itemize}
\tightlist
\item
  Max Kuhn. Chapter 14. Section 14.1
\end{itemize}

\end{frame}

\begin{frame}{Decision Boundary in Classification}
\protect\hypertarget{decision-boundary-in-classification}{}

Classification is a process of finding the \textbf{decision boundary}
that best separates two classes

\end{frame}

\begin{frame}{Decision Boundary in Classification}
\protect\hypertarget{decision-boundary-in-classification-1}{}

\includegraphics{images2/db.png}

\end{frame}

\begin{frame}{Decision Boundary in Classification}
\protect\hypertarget{decision-boundary-in-classification-2}{}

\includegraphics{images2/db1.png}

\begin{itemize}
\tightlist
\item
  SVM = Support Vector Machine
\end{itemize}

\end{frame}

\begin{frame}{Decision Tree}
\protect\hypertarget{decision-tree}{}

\begin{itemize}
\tightlist
\item
  Decision Tree for classification is \textbf{Classification Tree}
\item
  Decision Tree for Regression is \textbf{Regression Tree}
\end{itemize}

\end{frame}

\begin{frame}{Example of Classification Tree}
\protect\hypertarget{example-of-classification-tree}{}

\href{http://graphics8.nytimes.com/images/2008/04/16/us/0416-nat-subOBAMA.jpg}{Link}

\end{frame}

\begin{frame}{Example of Classification Tree}
\protect\hypertarget{example-of-classification-tree-1}{}

\includegraphics{images2/tree3.jpg}

\end{frame}

\begin{frame}{Example of Classification Tree}
\protect\hypertarget{example-of-classification-tree-2}{}

\includegraphics{images2/tree4.jpg}

\end{frame}

\begin{frame}{Classification Tree}
\protect\hypertarget{classification-tree}{}

\begin{itemize}
\tightlist
\item
  In two dimension, classification Tree's decision boundary is a
  collection of horiontal and vertical line
\end{itemize}

\end{frame}

\begin{frame}{Find a vertical line that best seperate \textbf{red} and
\textbf{green}.}
\protect\hypertarget{find-a-vertical-line-that-best-seperate-red-and-green.}{}

\includegraphics{fa_classification_tree2_files/figure-beamer/unnamed-chunk-1-1.pdf}

\end{frame}

\begin{frame}{One way to seperate the reds and greens}
\protect\hypertarget{one-way-to-seperate-the-reds-and-greens}{}

\includegraphics{fa_classification_tree2_files/figure-beamer/unnamed-chunk-2-1.pdf}

\end{frame}

\begin{frame}{One way to seperate the reds and greens}
\protect\hypertarget{one-way-to-seperate-the-reds-and-greens-1}{}

\includegraphics{fa_classification_tree2_files/figure-beamer/unnamed-chunk-3-1.pdf}

\end{frame}

\begin{frame}{One way to seperate the reds and greens}
\protect\hypertarget{one-way-to-seperate-the-reds-and-greens-2}{}

\includegraphics{fa_classification_tree2_files/figure-beamer/unnamed-chunk-4-1.pdf}

\end{frame}

\begin{frame}{Question}
\protect\hypertarget{question}{}

\begin{itemize}
\tightlist
\item
  \textbf{Question}: Which is the best split?
\end{itemize}

\end{frame}

\begin{frame}{Partial Answer}
\protect\hypertarget{partial-answer}{}

\begin{itemize}
\tightlist
\item
  It looks like Split 1 and 3 are better than Split 2 since it
  misclassifies less
\end{itemize}

\end{frame}

\begin{frame}{Partial Answer}
\protect\hypertarget{partial-answer-1}{}

\begin{itemize}
\tightlist
\item
  Which is the better split between Split 1 and Split 3?
\end{itemize}

\end{frame}

\begin{frame}{Partial Answer}
\protect\hypertarget{partial-answer-2}{}

\begin{itemize}
\tightlist
\item
  We need to find a way to measure \emph{how good a split is}
\end{itemize}

\end{frame}

\begin{frame}{Impurity Measure}
\protect\hypertarget{impurity-measure}{}

\begin{itemize}
\tightlist
\item
  The impurity of a node (\textbf{a node = a subset of the data or the
  original data}) measure how uncertain the node is.
\end{itemize}

\end{frame}

\begin{frame}{Impurity Measure}
\protect\hypertarget{impurity-measure-1}{}

\begin{itemize}
\tightlist
\item
  For example, node A with 50\% reds and 50\% greens would be more
  uncertained than node B with 90\% reds and 10\% greens. Thus, node A
  has greater impurity than node B.
\end{itemize}

\end{frame}

\begin{frame}{Impurity Measure}
\protect\hypertarget{impurity-measure-2}{}

\begin{itemize}
\tightlist
\item
  More uncertained \(=\) Greater impurity
\end{itemize}

\end{frame}

\begin{frame}{Children Impurity}
\protect\hypertarget{children-impurity}{}

\begin{itemize}
\tightlist
\item
  A split resulting smaller children impurity is a \textbf{better split}
\end{itemize}

\end{frame}

\begin{frame}{Children Impurity (\(I_{children}\))}
\protect\hypertarget{children-impurity-i_children}{}

\includegraphics{images2/parent_child.png}

\[
I_{children} = \frac{N_{left}}{N}I_{left} + \frac{N_{right}}{N}I_{right}
\]

\begin{itemize}
\tightlist
\item
  \(N_{left}\) and \(N_{right}\) are the number of points in the left
  child node and right child node, respectively.
\item
  \(N_{left}+N_{right}=N\)
\end{itemize}

\end{frame}

\begin{frame}{Impurity Measure}
\protect\hypertarget{impurity-measure-3}{}

\begin{itemize}
\tightlist
\item
  Impurity can be measured by: classification error, Gini Index, and
  Entropy.
\end{itemize}

\end{frame}

\begin{frame}{Impurity Measure}
\protect\hypertarget{impurity-measure-4}{}

\begin{itemize}
\tightlist
\item
  Let \(p_0\) and \(p_1\) be the proportion of class 0 and class 1 in a
  node.
\end{itemize}

\[
{\text{By Classification Error: }} I = min\{p_0, p_1\}
\]

\[
{\text{By Gini Index: }} I= 1 - p_0^2-p_1^2 
\]

\[
{\text{By Entropy: }} I = -p_0 \log_2(p_0)-p_1\log_2(p_1) 
\]

\end{frame}

\begin{frame}{Calculation}
\protect\hypertarget{calculation}{}

\begin{itemize}
\tightlist
\item
  Let's calculate the Children Impurity (\(I_{children}\)) of the three
  splits to decide which split is the best
\end{itemize}

\end{frame}

\begin{frame}{Split 1: Impurity by Classification Error}
\protect\hypertarget{split-1-impurity-by-classification-error}{}

\begin{itemize}
\tightlist
\item
  Let \textbf{green} and \textbf{red} be class 0 and class 1,
  respectively.
\end{itemize}

For Split 1: \(N = 5, N_{left} =1, N_{right} = 4\)

\includegraphics{images2/im1.png}

\end{frame}

\begin{frame}{Split 1: Impurity by Classification Error}
\protect\hypertarget{split-1-impurity-by-classification-error-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L:
  \(p_0 = \frac{0}{1} = 0, p_1 = \frac{1}{1} = 1\). Thus,
  \(I_{L} = \text{min}(0, 1) = 0\)
\item
  Node \emph{child right,} R: \(p_0 = \frac{3}{4}, p_1 = \frac{1}{4}\).
  Thus, \(I_{R} = \text{min}(\frac{3}{4}, \frac{1}{4}) = \frac{1}{4}\)
\item
  Children Impurity of Split 1:
\end{itemize}

\[
I_{children} = \frac{N_{left}}{N}I_{L} + \frac{N_{right}}{N}I_{R}
\]

\[     = \frac{1}{5} \cdot 0 + \frac{4}{5} \cdot \frac{1}{4} = 0.2\]

\end{frame}

\begin{frame}{Split 2: Impurity by Classification Error}
\protect\hypertarget{split-2-impurity-by-classification-error}{}

For Split 2: \(N = 5, N_{left} =2, N_{right} = 3\)

\includegraphics{images2/im3.png}

\end{frame}

\begin{frame}{Split 2: Impurity by Classification Error}
\protect\hypertarget{split-2-impurity-by-classification-error-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L: \(p_0 = \frac{1}{2}, p_1 = \frac{1}{2}\).
  Thus, \(I_{L} = \frac{1}{2}\)
\item
  Node \emph{child right,} R: \(p_0 = \frac{2}{3}, p_1 = \frac{1}{3}\).
  Thus, \(I_{R} = \text{min}(\frac{2}{3}, \frac{1}{3}) = \frac{1}{3}\)
\item
  Children Impurity of Split 2:
\end{itemize}

\[
I_{children} = \frac{N_{left}}{N}I_{L} + \frac{N_{right}}{N}I_{R}
\]

\[ = \frac{2}{5} \cdot \frac{1}{2} + \frac{3}{5} \cdot \frac{1}{3} = 0.4\]

\end{frame}

\begin{frame}{Split 3: Impurity by Classification Error}
\protect\hypertarget{split-3-impurity-by-classification-error}{}

For Split 3: \(N = 5, N_{left} =3, N_{right} = 2\)

\includegraphics{images2/im2.png}

\end{frame}

\begin{frame}{Split 3: Impurity by Classification Error}
\protect\hypertarget{split-3-impurity-by-classification-error-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L: \(p_0 = \frac{1}{3}, p_1 = \frac{2}{3}\).
  Thus, \(I_{A} = \text{min}(\frac{1}{3}, \frac{2}{3}) = \frac{1}{3}\)
\item
  Node \emph{child right,} R: \(p_0 = \frac{2}{2}, p_1 = \frac{0}{2}\).
  Thus, \(I_{R} = \text{min}(1,0) = 0\)
\item
  Children Impurity of Split 3:
\end{itemize}

\[
I_{children} = \frac{N_{left}}{N}I_{L} + \frac{N_{right}}{N}I_{R}
\]

\[ =  \frac{3}{5} \cdot \frac{1}{3} + \frac{2}{5} \cdot 0 = 0.2\]

\end{frame}

\begin{frame}{Comparing Impurity by Classification Error}
\protect\hypertarget{comparing-impurity-by-classification-error}{}

\begin{longtable}[]{@{}ll@{}}
\toprule
& \(I_{children}\)\tabularnewline
\midrule
\endhead
Split 1 & 0.2\tabularnewline
Split 2 & 0.4\tabularnewline
Split 3 & 0.2\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  By classification error, Split 1 and Split 3 are tie as the best
  because they have the same Children Impurity (\(I_{children}\)).
\end{itemize}

\end{frame}

\begin{frame}{Split 1: Impurity by Gini Index}
\protect\hypertarget{split-1-impurity-by-gini-index}{}

For Split 1: \(N = 5, N_{left} =1, N_{right} = 4\)

\includegraphics{images2/im1.png}

\end{frame}

\begin{frame}{Split 1: Impurity by Gini Index}
\protect\hypertarget{split-1-impurity-by-gini-index-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L:
  \(p_0 = \frac{0}{1} = 0, p_1 = \frac{1}{1} = 1\). Thus,
  \[I_{L} = 1 -0^2-1^2 = 0\]
\item
  Node \emph{child right,} R: \(p_0 = \frac{3}{4}, p_1 = \frac{1}{4}\).
  Thus, \[I_{R} = 1-(\frac{3}{4})^2-(\frac{1}{4})^2 = 0.375\]
\item
  Children Impurity of Split 1:
\end{itemize}

\[
I_{children} =  \frac{N_{left}}{N}I_{L} + \frac{N_{right}}{N}I_{R}
\]

\[ = \frac{1}{5} \cdot 0 + \frac{4}{5} \cdot 0.375 = 0.3\]

\end{frame}

\begin{frame}{Split 2: Impurity by Gini Index}
\protect\hypertarget{split-2-impurity-by-gini-index}{}

For Split 2: \(N = 5, N_{left} =2, N_{right} = 3\)

\includegraphics{images2/im3.png}

\end{frame}

\begin{frame}{Split 2: Impurity by Gini Index}
\protect\hypertarget{split-2-impurity-by-gini-index-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L: \(p_0 = \frac{1}{2}, p_1 = \frac{1}{2}\).
  Thus, \(I_{L} = 1- (\frac{1}{2})^2-(\frac{1}{2})^2=0.5\)
\item
  Node \emph{child right,} R: \(p_0 = \frac{2}{3}, p_1 = \frac{1}{3}\).
  Thus, \(I_{R} = 1-(\frac{2}{3})^2 -(\frac{1}{3})^2 = 0.44\)
\item
  Children Impurity of Split 2:
\end{itemize}

\[
I_{children} =  \frac{N_{left}}{N}I_{L} + \frac{N_{right}}{N}I_{R}
\]

\[ = \frac{2}{5} \cdot \frac{1}{2} + \frac{3}{5} \cdot 0.44 = 0.464\]

\end{frame}

\begin{frame}{Split 3: Impurity by Gini Index}
\protect\hypertarget{split-3-impurity-by-gini-index}{}

For Split 3: \(N = 5, N_{left} =3, N_{right} = 2\)

\includegraphics{images2/im2.png}

\end{frame}

\begin{frame}{Split 3: Impurity by Gini Index}
\protect\hypertarget{split-3-impurity-by-gini-index-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L: \(p_0 = \frac{1}{3}, p_1 = \frac{2}{3}\).
  Thus, \(I_{A} = 1-(\frac{1}{3})^2 -(\frac{2}{3})^2 = 0.44\)
\item
  Node \emph{child right,} R: \(p_0 = \frac{2}{2}, p_1 = \frac{0}{2}\).
  Thus, \(I_{R} = 1-0^2-1^2 = 0\)
\item
  Children Impurity of Split 3:
\end{itemize}

\[
I_{children} =  \frac{N_{left}}{N}I_{L} + \frac{N_{right}}{N}I_{R}
\]

\[ = \frac{3}{5} \cdot 0.44 + \frac{2}{5} \cdot 0 = 0.184\]

\end{frame}

\begin{frame}{Comparing Impurity by Gini Index}
\protect\hypertarget{comparing-impurity-by-gini-index}{}

\begin{longtable}[]{@{}ll@{}}
\toprule
& \(I_{children}\)\tabularnewline
\midrule
\endhead
Split 1 & 0.3\tabularnewline
Split 2 & 0.464\tabularnewline
Split 3 & 0.184\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  By Gini Index, Split 3 is the best because it has the smallest
  Children Impurity (\(I_{children}\)).
\end{itemize}

\end{frame}

\begin{frame}{Split 1: Impurity by Entropy}
\protect\hypertarget{split-1-impurity-by-entropy}{}

For Split 1: \(N = 5, N_{left} =1, N_{right} = 4\)

\includegraphics{images2/im1.png}

\end{frame}

\begin{frame}{Split 1: Impurity by Entropy}
\protect\hypertarget{split-1-impurity-by-entropy-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L:
  \(p_0 = \frac{0}{1} = 0, p_1 = \frac{1}{1} = 1\). Thus, \(I_{L} = 0\)
\item
  Node \emph{child right,} R: \(p_0 = \frac{3}{4}, p_1 = \frac{1}{4}\).
  Thus, \[I_{R} = -log_2(\frac{3}{4})-log_2(\frac{1}{4}) = 0.811\]
\item
  Children Impurity of Split 1:
\end{itemize}

\[
I_{children} =  \frac{N_{left}}{N}I_{L} + \frac{N_{right}}{N}I_{R}
\]

\[ = \frac{1}{5} \cdot 0 + \frac{4}{5} \cdot 0.811 = 0.649\]

\end{frame}

\begin{frame}{Split 2: Impurity by Entropy}
\protect\hypertarget{split-2-impurity-by-entropy}{}

For Split 2: \(N = 5, N_{left} =2, N_{right} = 3\)

\includegraphics{images2/im3.png}

\end{frame}

\begin{frame}{Split 2: Impurity by Entropy}
\protect\hypertarget{split-2-impurity-by-entropy-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L: \(p_0 = \frac{1}{2}, p_1 = \frac{1}{2}\).
  Thus, \(I_{L} = - log_1(\frac{1}{2})-log_2(\frac{1}{2})=1\)
\item
  Node \emph{child right,} R: \(p_0 = \frac{2}{3}, p_1 = \frac{1}{3}\).
  Thus, \(I_{R} = -log_2(\frac{2}{3}) -log_2(\frac{1}{3}) = 0.918\)
\item
  Children Impurity of Split 2: \[
  I_{children} =  \frac{N_{left}}{N}I_{L}+\frac{N_{right}}{N}I_{R}
  \]
\end{itemize}

\[ = \frac{2}{5} \cdot 1 + \frac{3}{5} \cdot 0.918 = 0.951\]

\end{frame}

\begin{frame}{Split 3: Impurity by Entropy}
\protect\hypertarget{split-3-impurity-by-entropy}{}

For Split 3: \(N = 5, N_{left} =3, N_{right} = 2\)

\includegraphics{images2/im2.png}

\end{frame}

\begin{frame}{Split 3: Impurity by Entropy}
\protect\hypertarget{split-3-impurity-by-entropy-1}{}

\begin{itemize}
\item
  Node \emph{child left,} L: \(p_0 = \frac{1}{3}, p_1 = \frac{2}{3}\).
  Thus, \(I_{A} = -log_2(\frac{1}{3}) -log_2(\frac{2}{3}) = 0.918\)
\item
  Node \emph{child right,} R: \(p_0 = \frac{2}{2}, p_1 = \frac{0}{2}\).
  Thus, \(I_{R} = 0\)
\item
  Children Impurity of Split 3:
\end{itemize}

\[
I_{children} =  \frac{N_{left}}{N}I_{L} + \frac{N_{right}}{N}I_{R}
\]

\[                            = \frac{3}{5} \cdot 0.918 + \frac{2}{5} \cdot 0 = 0.551\]

\end{frame}

\begin{frame}{Comparing Impurity by Entropy}
\protect\hypertarget{comparing-impurity-by-entropy}{}

\begin{longtable}[]{@{}ll@{}}
\toprule
& \(I_{children}\)\tabularnewline
\midrule
\endhead
Split 1 & 0.649\tabularnewline
Split 2 & 0.951\tabularnewline
Split 3 & 0.551\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  By Gini Index, Split 3 is the best because it has the smallest
  Children Impurity (\(I_{children}\)).
\end{itemize}

\end{frame}

\begin{frame}{Comparing Impurity Measures}
\protect\hypertarget{comparing-impurity-measures}{}

\includegraphics{images2/i.png}

\begin{itemize}
\tightlist
\item
  Relation between impurity and the class probabilities. All impurity
  measures are maximized at \textbf{\(p_1 =1/2\)} and minimized at
  \textbf{\(p_1 = 0\)} and \textbf{\(p_1=1\)}.\\
\end{itemize}

\end{frame}

\begin{frame}{Another Example}
\protect\hypertarget{another-example}{}

\includegraphics{images2/i1.png} - Which split is better?

\end{frame}

\begin{frame}{Decide the best split using Chi-Square test of
Independence}
\protect\hypertarget{decide-the-best-split-using-chi-square-test-of-independence}{}

\begin{itemize}
\tightlist
\item
  Besides Children Impurity, one can use the Chi-square, \(\chi^2\),
  test of independence to decide the best split.
\end{itemize}

\end{frame}

\begin{frame}{Review of Chi-Square test of Independence}
\protect\hypertarget{review-of-chi-square-test-of-independence}{}

\begin{itemize}
\tightlist
\item
  Let \(X\) and \(Y\) be two categorical variables.
\item
  We want to test if \(X\) and \(Y\) are independent/associated

  \begin{itemize}
  \tightlist
  \item
    \(H_0\): \(X\) and \(Y\) are independent
  \item
    \(H_{\alpha}:\) \(X\) and \(Y\) are dependent
  \end{itemize}
\item
  Test statistic:
\end{itemize}

\[\sum\frac{(e_i-o_i)^2}{e_i} \sim \chi^2 \text{ distribution with degree of freedom} (n-1)(m-1)\]

\end{frame}

\begin{frame}{Review of Chi-Square test of Independence}
\protect\hypertarget{review-of-chi-square-test-of-independence-1}{}

\begin{itemize}
\tightlist
\item
  In our context, the greater the \(\chi^2\) value, the smaller the
  \(p-value\)
\item
  The smaller the \(p-value\), the more dependent the two variables are.
  Thus the better the split is.
\item
  Therefore, we look for the split with the \textbf{greatest \(\chi^2\)
  value.}
\end{itemize}

\end{frame}

\begin{frame}{Applying to Our Example}
\protect\hypertarget{applying-to-our-example}{}

\begin{itemize}
\tightlist
\item
  We will calculate the \(\chi^2\) values of the three splits.\\
\item
  The best split is the split with the greatest \(\chi^2\) value.
\end{itemize}

\end{frame}

\begin{frame}{Split 1}
\protect\hypertarget{split-1}{}

\includegraphics{images2/im1.png}

\begin{longtable}[]{@{}llll@{}}
\toprule
& Greens & Reds & Total\tabularnewline
\midrule
\endhead
Left Branch & 0 & 1 & 1\tabularnewline
Right Branch & 3 & 1 & 4\tabularnewline
Total & 3 & 2 &\tabularnewline
\bottomrule
\end{longtable}

\end{frame}

\begin{frame}{Split 1}
\protect\hypertarget{split-1-1}{}

\[\chi^2 = \frac{(e_1-o_1)^2}{e_1}+\frac{(e_2-o_2)^2}{e_2}+\frac{(e_3-o_3)^2}{e_3}+\frac{(e_4-o_4)^2}{e_4}\]

\begin{itemize}
\item
  \(i=1\) (Cell 1): \(e_1 = \frac{1\cdot 3}{5}\), \(o_1 = 0\)
\item
  \(i=2\) (Cell 2): \(e_2 = \frac{1\cdot 2}{5}\), \(o_2 = 1\)
\item
  \(i=3\) (Cell 3): \(e_3 = \frac{3\cdot 4}{5}\), \(o_3 = 3\)
\item
  \(i=4\) (Cell 4): \(e_4 = \frac{2\cdot 4}{5}\), \(o_4 = 1\)
\item
  Plug in, we have: \[\chi^2 = 1.875\]
\end{itemize}

\end{frame}

\begin{frame}{Split 2}
\protect\hypertarget{split-2}{}

\includegraphics{images2/im3.png}

\begin{longtable}[]{@{}llll@{}}
\toprule
& Greens & Reds & Total\tabularnewline
\midrule
\endhead
Left Branch & 1 (Cell 1) & 1 (Cell 2) & 2\tabularnewline
Right Branch & 2 (Cell 3) & 1 (Cell 4) & 3\tabularnewline
Total & 3 & 2 &\tabularnewline
\bottomrule
\end{longtable}

\end{frame}

\begin{frame}{Split 2}
\protect\hypertarget{split-2-1}{}

\[\chi^2 = \frac{(e_1-o_1)^2}{e_1}+\frac{(e_2-o_2)^2}{e_2}+\frac{(e_3-o_3)^2}{e_3}+\frac{(e_4-o_4)^2}{e_4}\]

\begin{itemize}
\item
  \(i=1\) (Cell 1): \(e_1 = \frac{2\cdot 3}{5}\), \(o_1 = 1\)
\item
  \(i=2\) (Cell 2): \(e_2 = \frac{2\cdot 2}{5}\), \(o_2 = 1\)
\item
  \(i=3\) (Cell 3): \(e_3 = \frac{3\cdot 3}{5}\), \(o_3 = 2\)
\item
  \(i=4\) (Cell 4): \(e_4 = \frac{3\cdot 2}{5}\), \(o_4 = 1\)
\item
  Plug in, we have: \[\chi^2 = 0.139\]
\end{itemize}

\end{frame}

\begin{frame}{Split 3}
\protect\hypertarget{split-3}{}

\includegraphics{images2/im2.png}

\begin{longtable}[]{@{}llll@{}}
\toprule
& Greens & Reds & Total\tabularnewline
\midrule
\endhead
Left Branch & 1 (Cell 1) & 2 (Cell 2) & 3\tabularnewline
Right Branch & 2 (Cell 3) & 0 (Cell 4) & 2\tabularnewline
Total & 3 & 2 &\tabularnewline
\bottomrule
\end{longtable}

\end{frame}

\begin{frame}{Split 3}
\protect\hypertarget{split-3-1}{}

\[\chi^2 = \frac{(e_1-o_1)^2}{e_1}+\frac{(e_2-o_2)^2}{e_2}+\frac{(e_3-o_3)^2}{e_3}+\frac{(e_4-o_4)^2}{e_4}\]

\begin{itemize}
\item
  (Cell 1): \(e_1 = \frac{2\cdot 3}{5}\), \(o_1 = 1\)
\item
  (Cell 2): \(e_2 = \frac{2\cdot 2}{5}\), \(o_2 = 2\)
\item
  (Cell 3): \(e_3 = \frac{3\cdot 3}{5}\), \(o_3 = 2\)
\item
  (Cell 4): \(e_4 = \frac{3\cdot 2}{5}\), \(o_4 = 0\)
\item
  Plug in, we have: \[\chi^2 = 2.222\]
\end{itemize}

\end{frame}

\begin{frame}{Comparing the three splits}
\protect\hypertarget{comparing-the-three-splits}{}

\begin{longtable}[]{@{}ll@{}}
\toprule
& \(\chi^2\)\tabularnewline
\midrule
\endhead
Split 1 & 1.875\tabularnewline
Split 2 & 0.139\tabularnewline
Split 3 & 2.222\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  Split 3 is the best because it has the greatest \(\chi^2\)!
\end{itemize}

\end{frame}

\begin{frame}{Logworth}
\protect\hypertarget{logworth}{}

\begin{itemize}
\item
  The quality of the split can be measured by \textbf{Logworth}
\item
  Formula: \[
  logworth = -log(p_{value})
  \]
\item
  The greater the logworth, the better the split
\end{itemize}

\end{frame}

\begin{frame}{Logworth}
\protect\hypertarget{logworth-1}{}

\begin{longtable}[]{@{}llll@{}}
\toprule
& \(\chi^2\) & p-value & logworth\tabularnewline
\midrule
\endhead
Split 1 & 1.875 & 0.114 & 0.943\tabularnewline
Split 2 & 0.139 & 0.998 & 0.0008\tabularnewline
Split 3 & 2.222 & 0.088 & 1.055\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\item
  Greatest \(\chi^2\) = Lowest \(p-value\) = Greatest logworth = Best
  Split
\item
  Split 3 is the best split!
\end{itemize}

\end{frame}

\begin{frame}{What happens after the first split?}
\protect\hypertarget{what-happens-after-the-first-split}{}

\begin{itemize}
\tightlist
\item
  After the first split, the data are divided into to subsets.
\item
  The splitting process is repeated for each subset.
\item
  The process ends when a stopping criteria is satisfied
\end{itemize}

\end{frame}

\begin{frame}{Stopping Criteria}
\protect\hypertarget{stopping-criteria}{}

\begin{itemize}
\tightlist
\item
  Minimum Leaf Size: The minimum of observations in the leaves
\item
  Maximum Number of Leaves
\item
  Maximum Depth
\item
  Others
\end{itemize}

\end{frame}

\begin{frame}{Stopping Criteria}
\protect\hypertarget{stopping-criteria-1}{}

\includegraphics{images2/tree6.png}

\end{frame}

\begin{frame}{Decision Tree Algorithm - How to grow a tree}
\protect\hypertarget{decision-tree-algorithm---how-to-grow-a-tree}{}

\begin{itemize}
\tightlist
\item
  Step 1: Calculate the Children Impurity or \(p-value\) of all possible
  splits at all variables
\item
  Step 2: Select the split that give the minimum Children Impurity or
  lowest \(p-value\) to split the data into two subdata \(D_1\) and
  \(D_2\)
\item
  Repeat \emph{Step 1} and \emph{Step 2} to both \(D_1\) and \(D_2\).
\item
  Until a stopping criteria is satisfied
\end{itemize}

\end{frame}

\begin{frame}{Complexity of Decision Tree}
\protect\hypertarget{complexity-of-decision-tree}{}

\begin{itemize}
\tightlist
\item
  A complexity of a tree can be measured by the number of leaves the
  tree has
\item
  The more leaves a tree has, the more complex the tree is.
\item
  A complex tree may be \textbf{overfitted}, i.e.~having low training
  error but high testing error.
\end{itemize}

\end{frame}

\begin{frame}{Prunning a tree}
\protect\hypertarget{prunning-a-tree}{}

\begin{itemize}
\tightlist
\item
  For any given data, one can construct a tree that achives 0
  misclassification on training data
\item
  After growing the tree one needs to prune it to avoid overfittted
\end{itemize}

\end{frame}

\begin{frame}{Prunning a tree}
\protect\hypertarget{prunning-a-tree-1}{}

\begin{itemize}
\tightlist
\item
  The tree with maximum number of leaves is called the \textbf{maximal
  tree} (still satisfied the stopping rule)
\item
  From the \textbf{maximal tree}, leaves are cut down, one by one, to
  obatined all possible subtrees
\item
  The subtree with lowest error on validation data, is the
  \textbf{optimal tree}
\end{itemize}

\end{frame}

\begin{frame}{Maximal vs Optimal Tree}
\protect\hypertarget{maximal-vs-optimal-tree}{}

\includegraphics{images2/tree7.png}

\end{frame}

\begin{frame}{Example of Tree Prunning}
\protect\hypertarget{example-of-tree-prunning}{}

\includegraphics{images2/tree8.png}

\end{frame}

\begin{frame}{Example of Tree Prunning}
\protect\hypertarget{example-of-tree-prunning-1}{}

\includegraphics{images2/tree9.png}

\begin{itemize}
\item
  All the subtrees A, B, C, D, and E will be validated with the
  validation data to find the \textbf{optimal tree}
\item
  The \textbf{optimal tree} could be the \textbf{maximal tree}!
\end{itemize}

\end{frame}

\begin{frame}{Question}
\protect\hypertarget{question-1}{}

\includegraphics{images2/tree9.png} - What if both B and C give the
lowest error on the validation data? Which tree should be selected as
the final model?

\end{frame}

\end{document}
